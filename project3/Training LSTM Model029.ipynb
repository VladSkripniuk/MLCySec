{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATASET_DIR = './data/'\n",
    "GLOVE_DIR = './glove.6B/'\n",
    "SAVE_DIR = './'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
    "y = X['domain1_score']\n",
    "X = X.dropna(axis=1)\n",
    "# X = X.drop(columns=['rater1_domain1', 'rater2_domain1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['rater1_domain1', 'rater2_domain1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              8  \n",
       "1              9  \n",
       "2              7  \n",
       "3             10  \n",
       "4              8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12976"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_set</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           essay_id\n",
       "essay_set          \n",
       "1              1783\n",
       "2              1800\n",
       "3              1726\n",
       "4              1770\n",
       "5              1805\n",
       "6              1800\n",
       "7              1569\n",
       "8               723"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of essays in each essay set\n",
    "X.groupby(by='essay_set').count().drop(['essay', 'domain1_score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay_id                                                     20716\n",
       "essay_set                                                        8\n",
       "essay             A long time ago when I was in third grade I h...\n",
       "domain1_score                                                   34\n",
       "Name: 12253, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X['essay_set'] == 8].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum and Maximum Scores for each essay set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay_set\n",
       "1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "3    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "4    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "5    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "6    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "7    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "8    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: domain1_score, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns8y50JuZZc6F3swscy70ZmaZ+/9QGWgh+yAQ7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10d9cae3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.groupby(by='essay_set')['domain1_score'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAJCCAYAAADz6dIfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10d9baa080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(10,10))\n",
    "\n",
    "for i in range(1, 9):\n",
    "    ax[(i-1)//2][(i-1)%2].hist(X[X['essay_set'] == i]['domain1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minimum_scores = [-1, 2, 1, 0, 0, 0, 0, 0, 0]\n",
    "maximum_scores = [-1, 12, 6, 3, 3, 4, 4, 30, 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will preprocess all essays and convert them to feature vectors so that they can be fed into the RNN.\n",
    "\n",
    "These are all helper functions used to clean the essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skripniuk/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def essay_to_wordlist(essay_v, remove_stopwords):\n",
    "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
    "    words = essay_v.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return (words)\n",
    "\n",
    "def essay_to_sentences(essay_v, remove_stopwords):\n",
    "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            featureVec = np.add(featureVec,model[word])        \n",
    "    featureVec = np.divide(featureVec,num_words)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a 2-Layer LSTM Model. \n",
    "\n",
    "Note that instead of using sigmoid activation in the output layer we will use\n",
    "Relu since we are not normalising training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_model = load_model('model_weights/final_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model on the dataset.\n",
    "\n",
    "We will use 5-Fold Cross Validation and measure the Quadratic Weighted Kappa for each fold.\n",
    "We will then calculate Average Kappa for all the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_from_bin = KeyedVectors.load_word2vec_format(\"word2vecmodel.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_essays = X['essay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300 \n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_essays = []\n",
    "for essay_v in test_essays:\n",
    "    clean_test_essays.append(essay_to_wordlist( essay_v, remove_stopwords=True ))\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_essays, wv_from_bin, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataVecs = np.array(testDataVecs)\n",
    "# Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = X['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa Score: 0.9627824918083597\n"
     ]
    }
   ],
   "source": [
    "y_pred = lstm_model.predict(testDataVecs)\n",
    "    \n",
    "# Round y_pred to the nearest integer.\n",
    "y_pred = np.around(y_pred)\n",
    "\n",
    "# Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "print(\"Kappa Score: {}\".format(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8500.,  815., 1533.,  509.,  632.,  229.,   98.,  106.,  203.,\n",
       "         351.]),\n",
       " array([ 0.,  4.,  8., 12., 16., 20., 24., 28., 32., 36., 40.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkjrKAJCkjjIAJKmjDABJ6qj/D3kwB/Qx94+XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f108f276630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 625., 4009., 3677.,  333.,  164.]),\n",
       " array([1, 2, 3, 4, 5, 6]),\n",
       " <a list of 5 Patch objects>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDJkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1085e3bfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred, range(1,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([110., 318., 652., 576., 226.,  79.,  80.,  99., 140., 190., 204.,\n",
       "        177., 149., 102.,  84.,  64.,  46.,  35.,  31.,  24.,  24.,  19.,\n",
       "         25.,  33.,  17.,  31.,  45.,  34.,  44.,  80.,  92., 102.,  93.,\n",
       "         55.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]),\n",
       " array([ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "        23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
       "        40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56,\n",
       "        57, 58, 59]),\n",
       " <a list of 53 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10853d8b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred, range(6,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa Score: essay set 1: 0.418003585079612\n",
      "Kappa Score: essay set 2: 0.06478513760444593\n",
      "Kappa Score: essay set 3: 0.11166796873466467\n",
      "Kappa Score: essay set 4: 0.20321438676152948\n",
      "Kappa Score: essay set 5: 0.2839883407487712\n",
      "Kappa Score: essay set 6: 0.31989011408294865\n",
      "Kappa Score: essay set 7: 0.6160905753003008\n",
      "Kappa Score: essay set 8: 0.3826673365953013\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9):\n",
    "    print(\"Kappa Score: essay set {0}: {1}\".format(i, cohen_kappa_score(y_test[X['essay_set']==i].values,y_pred[X['essay_set']==i],weights='quadratic')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.4119648928977989,\n",
    " 0.02591404408055986,\n",
    " 0.10877239100229052,\n",
    " 0.14880894311275894,\n",
    " 0.24700573449809748,\n",
    " 0.3031976418790343,\n",
    " 0.615828592182176,\n",
    " 0.38799451654242445]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data\t\t mysite      ScreenShots\r\n",
      " models\t\t README.md  'Training LSTM Model.ipynb'\r\n",
      " model_weights\t score\t     word2vecmodel.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score.score import quadratic_weighted_kappa, linear_weighted_kappa, kappa, mean_quadratic_weighted_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import numpy\n",
    "\n",
    "def confusion_matrix(rater_a, rater_b,\n",
    "         min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a)==len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(reduce(min, rater_a), reduce(min, rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(reduce(max, rater_a), reduce(max, rater_b))\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a,b in zip(rater_a,rater_b):\n",
    "        conf_mat[a-min_rating][b-min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None: min_rating = reduce(min, ratings)\n",
    "    if max_rating is None: max_rating = reduce(max, ratings)\n",
    "    num_ratings = max_rating - min_rating + 1\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r-min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "def quadratic_weighted_kappa(rater_a, rater_b,\n",
    "                             min_rating = None, max_rating = None):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    scoreQuadraticWeightedKappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1  \n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    \n",
    "    scoreQuadraticWeightedKappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    \n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "   \n",
    "    score_quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = numpy.array(rater_a).reshape((-1,))\n",
    "    rater_b = numpy.array(rater_b).reshape((-1,))\n",
    "    \n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(reduce(min, rater_a), reduce(min, rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(reduce(max, rater_a), reduce(max, rater_b))\n",
    "    \n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                     min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i]*hist_rater_b[j]\n",
    "                      / num_scored_items) \n",
    "            d = pow(i-j,2.0) / pow(num_ratings-1, 2.0)\n",
    "            numerator += d*conf_mat[i][j] / num_scored_items\n",
    "            denominator += d*expected_count / num_scored_items\n",
    "\n",
    "    return 1.0 - numerator / denominator\n",
    "\n",
    "def mean_quadratic_weighted_kappa(kappas, weights=None):\n",
    "    \"\"\"\n",
    "    Calculates the mean of the quadratic\n",
    "    weighted kappas after applying Fisher's r-to-z transform, which is\n",
    "    approximately a variance-stabilizing transformation.  This\n",
    "    transformation is undefined if one of the kappas is 1.0, so all kappa\n",
    "    values are capped in the range (-0.999, 0.999).  The reverse\n",
    "    transformation is then applied before returning the result.\n",
    "    \n",
    "    mean_quadratic_weighted_kappa(kappas), where kappas is a vector of\n",
    "    kappa values\n",
    "\n",
    "    mean_quadratic_weighted_kappa(kappas, weights), where weights is a vector\n",
    "    of weights that is the same size as kappas.  Weights are applied in the\n",
    "    z-space\n",
    "    \"\"\"\n",
    "    kappas = numpy.array(kappas, dtype=float)\n",
    "    if weights is None:\n",
    "        weights = numpy.ones(numpy.shape(kappas))\n",
    "    else:\n",
    "        weights = weights / numpy.mean(weights)\n",
    "\n",
    "    # ensure that kappas are in the range [-.999, .999]\n",
    "    kappas = numpy.array([min(x, .999) for x in kappas])\n",
    "    kappas = numpy.array([max(x, -.999) for x in kappas])\n",
    "    \n",
    "    z = 0.5 * numpy.log( (1+kappas)/(1-kappas) ) * weights\n",
    "    z = numpy.mean(z)\n",
    "    kappa = (numpy.exp(2*z)-1) / (numpy.exp(2*z)+1)\n",
    "    return kappa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reload() argument must be a module",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-efb85018085a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquadratic_weighted_kappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reload() argument must be a module\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__spec__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reload() argument must be a module"
     ]
    }
   ],
   "source": [
    "reload(quadratic_weighted_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(723,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[X['essay_set']==i].values.astype(int).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(723, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[X['essay_set']==i].astype(int).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4119648928977989,\n",
       " 0.02591404408055986,\n",
       " 0.10877239100229052,\n",
       " 0.14880894311275894,\n",
       " 0.24700573449809748,\n",
       " 0.3031976418790343,\n",
       " 0.615828592182176,\n",
       " 0.38799451654242445]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappas = [quadratic_weighted_kappa(\n",
    "    y_test[X['essay_set']==i].values.astype(int),y_pred[X['essay_set']==i].astype(int))\n",
    "          for i in range(1, 9)]\n",
    "kappas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2931389333073196"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_quadratic_weighted_kappa(kappas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ronitmankad/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10380/10380 [==============================] - 6s 601us/step - loss: 63.5235 - mean_absolute_error: 4.3085\n",
      "Epoch 2/50\n",
      "10380/10380 [==============================] - 4s 402us/step - loss: 38.5016 - mean_absolute_error: 3.4547\n",
      "Epoch 3/50\n",
      "10380/10380 [==============================] - 4s 406us/step - loss: 32.6369 - mean_absolute_error: 3.3775\n",
      "Epoch 4/50\n",
      "10380/10380 [==============================] - 4s 405us/step - loss: 30.2402 - mean_absolute_error: 3.3352\n",
      "Epoch 5/50\n",
      "10380/10380 [==============================] - 4s 402us/step - loss: 28.8526 - mean_absolute_error: 3.2857\n",
      "Epoch 6/50\n",
      "10380/10380 [==============================] - 4s 399us/step - loss: 27.0931 - mean_absolute_error: 3.1558\n",
      "Epoch 7/50\n",
      "10380/10380 [==============================] - 4s 400us/step - loss: 25.9112 - mean_absolute_error: 3.0514\n",
      "Epoch 8/50\n",
      "10380/10380 [==============================] - 4s 401us/step - loss: 24.2077 - mean_absolute_error: 2.8713\n",
      "Epoch 9/50\n",
      "10380/10380 [==============================] - 4s 405us/step - loss: 21.3049 - mean_absolute_error: 2.6915\n",
      "Epoch 10/50\n",
      "10380/10380 [==============================] - 5s 471us/step - loss: 18.6645 - mean_absolute_error: 2.5227\n",
      "Epoch 11/50\n",
      "10380/10380 [==============================] - 5s 481us/step - loss: 17.0862 - mean_absolute_error: 2.3953\n",
      "Epoch 12/50\n",
      "10380/10380 [==============================] - 5s 469us/step - loss: 16.5515 - mean_absolute_error: 2.3348\n",
      "Epoch 13/50\n",
      "10380/10380 [==============================] - 5s 471us/step - loss: 15.5819 - mean_absolute_error: 2.2491\n",
      "Epoch 14/50\n",
      "10380/10380 [==============================] - 5s 477us/step - loss: 14.2605 - mean_absolute_error: 2.1680\n",
      "Epoch 15/50\n",
      "10380/10380 [==============================] - 5s 476us/step - loss: 13.9900 - mean_absolute_error: 2.1280\n",
      "Epoch 16/50\n",
      "10380/10380 [==============================] - 5s 475us/step - loss: 13.4193 - mean_absolute_error: 2.1063\n",
      "Epoch 17/50\n",
      "10380/10380 [==============================] - 5s 480us/step - loss: 12.8282 - mean_absolute_error: 2.0642\n",
      "Epoch 18/50\n",
      "10380/10380 [==============================] - 5s 475us/step - loss: 12.9203 - mean_absolute_error: 2.0395\n",
      "Epoch 19/50\n",
      "10380/10380 [==============================] - 5s 496us/step - loss: 11.9574 - mean_absolute_error: 1.9789\n",
      "Epoch 20/50\n",
      "10380/10380 [==============================] - 5s 480us/step - loss: 11.8786 - mean_absolute_error: 1.9670\n",
      "Epoch 21/50\n",
      "10380/10380 [==============================] - 5s 476us/step - loss: 11.2761 - mean_absolute_error: 1.9160\n",
      "Epoch 22/50\n",
      "10380/10380 [==============================] - 5s 478us/step - loss: 11.4523 - mean_absolute_error: 1.9147\n",
      "Epoch 23/50\n",
      "10380/10380 [==============================] - 5s 481us/step - loss: 11.3838 - mean_absolute_error: 1.8938\n",
      "Epoch 24/50\n",
      "10380/10380 [==============================] - 5s 487us/step - loss: 10.6780 - mean_absolute_error: 1.8410\n",
      "Epoch 25/50\n",
      "10380/10380 [==============================] - 5s 489us/step - loss: 10.8487 - mean_absolute_error: 1.8455\n",
      "Epoch 26/50\n",
      "10380/10380 [==============================] - 5s 488us/step - loss: 10.2106 - mean_absolute_error: 1.8042\n",
      "Epoch 27/50\n",
      "10380/10380 [==============================] - 5s 496us/step - loss: 10.2350 - mean_absolute_error: 1.7975\n",
      "Epoch 28/50\n",
      "10380/10380 [==============================] - 5s 485us/step - loss: 9.9869 - mean_absolute_error: 1.7642\n",
      "Epoch 29/50\n",
      "10380/10380 [==============================] - 5s 486us/step - loss: 9.8490 - mean_absolute_error: 1.7526\n",
      "Epoch 30/50\n",
      "10380/10380 [==============================] - 5s 486us/step - loss: 9.6549 - mean_absolute_error: 1.7326\n",
      "Epoch 31/50\n",
      "10380/10380 [==============================] - 5s 490us/step - loss: 9.8022 - mean_absolute_error: 1.7378\n",
      "Epoch 32/50\n",
      "10380/10380 [==============================] - 5s 500us/step - loss: 9.8464 - mean_absolute_error: 1.7237\n",
      "Epoch 33/50\n",
      "10380/10380 [==============================] - 5s 494us/step - loss: 10.1569 - mean_absolute_error: 1.7463\n",
      "Epoch 34/50\n",
      "10380/10380 [==============================] - 5s 487us/step - loss: 9.1788 - mean_absolute_error: 1.6925\n",
      "Epoch 35/50\n",
      "10380/10380 [==============================] - 5s 512us/step - loss: 9.0076 - mean_absolute_error: 1.6951\n",
      "Epoch 36/50\n",
      "10380/10380 [==============================] - 5s 487us/step - loss: 9.0089 - mean_absolute_error: 1.6783\n",
      "Epoch 37/50\n",
      "10380/10380 [==============================] - 5s 496us/step - loss: 8.4260 - mean_absolute_error: 1.6397\n",
      "Epoch 38/50\n",
      "10380/10380 [==============================] - 5s 507us/step - loss: 8.7338 - mean_absolute_error: 1.6523\n",
      "Epoch 39/50\n",
      "10380/10380 [==============================] - 5s 498us/step - loss: 8.6461 - mean_absolute_error: 1.6494\n",
      "Epoch 40/50\n",
      "10380/10380 [==============================] - 5s 500us/step - loss: 8.7413 - mean_absolute_error: 1.6475\n",
      "Epoch 41/50\n",
      "10380/10380 [==============================] - 5s 497us/step - loss: 8.5590 - mean_absolute_error: 1.6373\n",
      "Epoch 42/50\n",
      "10380/10380 [==============================] - 5s 487us/step - loss: 8.7883 - mean_absolute_error: 1.6457\n",
      "Epoch 43/50\n",
      "10380/10380 [==============================] - 5s 486us/step - loss: 8.2834 - mean_absolute_error: 1.6170\n",
      "Epoch 44/50\n",
      "10380/10380 [==============================] - 5s 495us/step - loss: 8.4489 - mean_absolute_error: 1.6228\n",
      "Epoch 45/50\n",
      "10380/10380 [==============================] - 5s 491us/step - loss: 8.4475 - mean_absolute_error: 1.6096\n",
      "Epoch 46/50\n",
      "10380/10380 [==============================] - 5s 505us/step - loss: 8.0236 - mean_absolute_error: 1.5914\n",
      "Epoch 47/50\n",
      "10380/10380 [==============================] - 5s 493us/step - loss: 8.2755 - mean_absolute_error: 1.6129\n",
      "Epoch 48/50\n",
      "10380/10380 [==============================] - 5s 491us/step - loss: 8.3037 - mean_absolute_error: 1.5814\n",
      "Epoch 49/50\n",
      "10380/10380 [==============================] - 5s 490us/step - loss: 8.6168 - mean_absolute_error: 1.5995\n",
      "Epoch 50/50\n",
      "10380/10380 [==============================] - 5s 493us/step - loss: 8.4063 - mean_absolute_error: 1.5982\n",
      "Kappa Score: 0.9613444398855562\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 8s 723us/step - loss: 62.2980 - mean_absolute_error: 4.2575\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 5s 506us/step - loss: 36.9081 - mean_absolute_error: 3.4606\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 5s 506us/step - loss: 31.8027 - mean_absolute_error: 3.4013\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 5s 438us/step - loss: 29.4525 - mean_absolute_error: 3.3367\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 5s 441us/step - loss: 27.6676 - mean_absolute_error: 3.2650\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 26.7322 - mean_absolute_error: 3.1840\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 5s 447us/step - loss: 25.1847 - mean_absolute_error: 3.0235\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 24.4046 - mean_absolute_error: 2.8881\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 5s 444us/step - loss: 22.0171 - mean_absolute_error: 2.7358\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 5s 447us/step - loss: 19.3726 - mean_absolute_error: 2.5699\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 5s 443us/step - loss: 16.9303 - mean_absolute_error: 2.3903\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 5s 448us/step - loss: 15.3077 - mean_absolute_error: 2.2563\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 5s 446us/step - loss: 14.9769 - mean_absolute_error: 2.2163\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 5s 450us/step - loss: 13.7733 - mean_absolute_error: 2.1543\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 5s 449us/step - loss: 13.2371 - mean_absolute_error: 2.1229\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 5s 445us/step - loss: 12.9251 - mean_absolute_error: 2.0820\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 5s 447us/step - loss: 12.6702 - mean_absolute_error: 2.0445\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 5s 449us/step - loss: 12.2949 - mean_absolute_error: 2.0036\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 11.7786 - mean_absolute_error: 1.9614\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 5s 458us/step - loss: 12.2178 - mean_absolute_error: 1.9645\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 5s 449us/step - loss: 11.7004 - mean_absolute_error: 1.9419\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 11.3668 - mean_absolute_error: 1.9114\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 5s 452us/step - loss: 11.3117 - mean_absolute_error: 1.8967\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 5s 449us/step - loss: 10.5058 - mean_absolute_error: 1.8363\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 5s 458us/step - loss: 10.6058 - mean_absolute_error: 1.8325\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 10.0056 - mean_absolute_error: 1.7887\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 10.2886 - mean_absolute_error: 1.7926\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 10.0554 - mean_absolute_error: 1.7655\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 5s 459us/step - loss: 10.1119 - mean_absolute_error: 1.7643\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 9.6685 - mean_absolute_error: 1.7534\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 9.7459 - mean_absolute_error: 1.7405\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 5s 485us/step - loss: 9.3286 - mean_absolute_error: 1.7137\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 5s 498us/step - loss: 9.6981 - mean_absolute_error: 1.7241\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 5s 481us/step - loss: 9.3469 - mean_absolute_error: 1.7090\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 5s 485us/step - loss: 9.0990 - mean_absolute_error: 1.6880\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 5s 485us/step - loss: 9.0683 - mean_absolute_error: 1.6725\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 5s 483us/step - loss: 9.0441 - mean_absolute_error: 1.6716\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 5s 487us/step - loss: 8.7532 - mean_absolute_error: 1.6419 1s - loss: 8.7212 - \n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 5s 488us/step - loss: 8.9524 - mean_absolute_error: 1.6685\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 5s 490us/step - loss: 8.4924 - mean_absolute_error: 1.6284\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 5s 492us/step - loss: 8.7462 - mean_absolute_error: 1.6474\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 5s 492us/step - loss: 8.4404 - mean_absolute_error: 1.6222\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 5s 494us/step - loss: 8.6403 - mean_absolute_error: 1.6335\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 5s 503us/step - loss: 8.4331 - mean_absolute_error: 1.6135\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 5s 487us/step - loss: 8.0298 - mean_absolute_error: 1.6018\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 4s 400us/step - loss: 8.1244 - mean_absolute_error: 1.5928\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 4s 406us/step - loss: 8.2598 - mean_absolute_error: 1.5919\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 4s 404us/step - loss: 8.2951 - mean_absolute_error: 1.5953\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 516us/step - loss: 8.2722 - mean_absolute_error: 1.5991\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 482us/step - loss: 8.2591 - mean_absolute_error: 1.5993\n",
      "Kappa Score: 0.9589832380634941\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 8s 742us/step - loss: 62.5675 - mean_absolute_error: 4.2637\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 5s 507us/step - loss: 38.3448 - mean_absolute_error: 3.4645\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 5s 507us/step - loss: 32.6267 - mean_absolute_error: 3.3669\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 5s 504us/step - loss: 30.1692 - mean_absolute_error: 3.3103\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 5s 502us/step - loss: 28.7610 - mean_absolute_error: 3.2371\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 5s 506us/step - loss: 27.9961 - mean_absolute_error: 3.1440\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 5s 503us/step - loss: 25.7321 - mean_absolute_error: 2.9703\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 5s 521us/step - loss: 22.0224 - mean_absolute_error: 2.7591\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 6s 536us/step - loss: 19.8124 - mean_absolute_error: 2.6059\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 5s 503us/step - loss: 18.1588 - mean_absolute_error: 2.4854\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 6s 596us/step - loss: 16.7148 - mean_absolute_error: 2.3875\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 5s 434us/step - loss: 16.1785 - mean_absolute_error: 2.3219\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 5s 486us/step - loss: 14.8489 - mean_absolute_error: 2.2284\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 4s 431us/step - loss: 14.3435 - mean_absolute_error: 2.1928\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 4s 432us/step - loss: 13.7165 - mean_absolute_error: 2.1590\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 6s 547us/step - loss: 13.3761 - mean_absolute_error: 2.0890\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 5s 484us/step - loss: 12.6187 - mean_absolute_error: 2.0184\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 5s 469us/step - loss: 12.5590 - mean_absolute_error: 2.0113\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 5s 468us/step - loss: 11.9494 - mean_absolute_error: 1.9737\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 5s 454us/step - loss: 11.9072 - mean_absolute_error: 1.9554\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 4s 419us/step - loss: 11.8927 - mean_absolute_error: 1.9263\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 5s 448us/step - loss: 11.4953 - mean_absolute_error: 1.8964\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 11.5313 - mean_absolute_error: 1.8920\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 5s 439us/step - loss: 10.7838 - mean_absolute_error: 1.8527\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 4s 424us/step - loss: 10.5869 - mean_absolute_error: 1.8215\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 5s 441us/step - loss: 10.3974 - mean_absolute_error: 1.8020\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 5s 444us/step - loss: 9.4939 - mean_absolute_error: 1.7357\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 4s 428us/step - loss: 10.0305 - mean_absolute_error: 1.7451\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 4s 423us/step - loss: 10.0401 - mean_absolute_error: 1.7483\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 5s 443us/step - loss: 9.4818 - mean_absolute_error: 1.7133\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 4s 420us/step - loss: 8.8647 - mean_absolute_error: 1.6773\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 4s 424us/step - loss: 9.5378 - mean_absolute_error: 1.7099\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 5s 439us/step - loss: 9.0718 - mean_absolute_error: 1.6817\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 4s 420us/step - loss: 9.3776 - mean_absolute_error: 1.6999\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 5s 467us/step - loss: 9.1884 - mean_absolute_error: 1.6775\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 4s 402us/step - loss: 9.0791 - mean_absolute_error: 1.6763\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 4s 403us/step - loss: 9.1158 - mean_absolute_error: 1.6657\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 4s 414us/step - loss: 9.1464 - mean_absolute_error: 1.6648\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 4s 424us/step - loss: 9.3851 - mean_absolute_error: 1.6691\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 5s 507us/step - loss: 8.4198 - mean_absolute_error: 1.6144\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 5s 500us/step - loss: 8.9949 - mean_absolute_error: 1.6546\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 6s 546us/step - loss: 8.4026 - mean_absolute_error: 1.6071\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 6s 552us/step - loss: 9.0455 - mean_absolute_error: 1.6385\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 6s 598us/step - loss: 8.8043 - mean_absolute_error: 1.6247\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 6s 580us/step - loss: 9.0148 - mean_absolute_error: 1.6404\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 6s 591us/step - loss: 8.4393 - mean_absolute_error: 1.5798\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 8.4115 - mean_absolute_error: 1.5962\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 5s 521us/step - loss: 8.3039 - mean_absolute_error: 1.5980\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 495us/step - loss: 9.0333 - mean_absolute_error: 1.6192\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 469us/step - loss: 8.3252 - mean_absolute_error: 1.5787\n",
      "Kappa Score: 0.9618648391087394\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 9s 847us/step - loss: 59.7070 - mean_absolute_error: 4.2050\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 6s 555us/step - loss: 38.0471 - mean_absolute_error: 3.4805\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 5s 519us/step - loss: 33.5351 - mean_absolute_error: 3.4316\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 6s 552us/step - loss: 30.5502 - mean_absolute_error: 3.3712\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 5s 510us/step - loss: 28.7989 - mean_absolute_error: 3.2883\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 7s 639us/step - loss: 28.5260 - mean_absolute_error: 3.2329\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 5s 470us/step - loss: 26.5483 - mean_absolute_error: 3.0610\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 24.6949 - mean_absolute_error: 2.8993\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 21.8455 - mean_absolute_error: 2.7113\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 20.1272 - mean_absolute_error: 2.5862\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 19.1692 - mean_absolute_error: 2.5056\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 5s 450us/step - loss: 17.5118 - mean_absolute_error: 2.3850\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 5s 454us/step - loss: 16.7526 - mean_absolute_error: 2.3295\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 6s 541us/step - loss: 16.2574 - mean_absolute_error: 2.2811\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 6s 585us/step - loss: 15.6072 - mean_absolute_error: 2.2214\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 5s 478us/step - loss: 14.9989 - mean_absolute_error: 2.1690\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 14.8320 - mean_absolute_error: 2.1662\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 6s 531us/step - loss: 13.1040 - mean_absolute_error: 2.0555\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 7s 677us/step - loss: 12.6551 - mean_absolute_error: 2.0237\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 5s 510us/step - loss: 12.3173 - mean_absolute_error: 2.0013\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 5s 463us/step - loss: 11.6261 - mean_absolute_error: 1.9586\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 5s 501us/step - loss: 11.3161 - mean_absolute_error: 1.9089\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 5s 440us/step - loss: 11.7520 - mean_absolute_error: 1.9279\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 4s 428us/step - loss: 11.1106 - mean_absolute_error: 1.8810\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 4s 414us/step - loss: 11.0889 - mean_absolute_error: 1.8581\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 4s 430us/step - loss: 10.9807 - mean_absolute_error: 1.8435\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 4s 421us/step - loss: 10.9244 - mean_absolute_error: 1.8338\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 4s 400us/step - loss: 10.6652 - mean_absolute_error: 1.7977\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 4s 419us/step - loss: 10.0984 - mean_absolute_error: 1.7716\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 4s 401us/step - loss: 10.0962 - mean_absolute_error: 1.7613\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 4s 423us/step - loss: 10.0946 - mean_absolute_error: 1.7547\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 4s 407us/step - loss: 9.8874 - mean_absolute_error: 1.7351\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 6s 550us/step - loss: 9.7172 - mean_absolute_error: 1.7241\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 7s 634us/step - loss: 9.4290 - mean_absolute_error: 1.6996\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 6s 612us/step - loss: 9.6284 - mean_absolute_error: 1.7127\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 6s 536us/step - loss: 9.5775 - mean_absolute_error: 1.7034\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 5s 476us/step - loss: 9.5176 - mean_absolute_error: 1.6929\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 6s 575us/step - loss: 9.4747 - mean_absolute_error: 1.6902\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 6s 591us/step - loss: 9.2118 - mean_absolute_error: 1.6689\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 5s 494us/step - loss: 9.0569 - mean_absolute_error: 1.6607\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 5s 494us/step - loss: 8.7025 - mean_absolute_error: 1.6405\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 5s 494us/step - loss: 8.9474 - mean_absolute_error: 1.6552\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 5s 466us/step - loss: 8.6041 - mean_absolute_error: 1.6390\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 5s 512us/step - loss: 8.4721 - mean_absolute_error: 1.6096\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.8245 - mean_absolute_error: 1.6373\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 5s 478us/step - loss: 8.8140 - mean_absolute_error: 1.6371\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 5s 472us/step - loss: 8.8156 - mean_absolute_error: 1.6405\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 5s 486us/step - loss: 8.8260 - mean_absolute_error: 1.6162\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 472us/step - loss: 8.4901 - mean_absolute_error: 1.6138\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 475us/step - loss: 8.2818 - mean_absolute_error: 1.6037\n",
      "Kappa Score: 0.9654185652735067\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 9s 856us/step - loss: 66.8658 - mean_absolute_error: 4.4002\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 5s 503us/step - loss: 39.8854 - mean_absolute_error: 3.5374\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 5s 492us/step - loss: 33.5379 - mean_absolute_error: 3.4505\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 7s 652us/step - loss: 30.7586 - mean_absolute_error: 3.3854\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 7s 694us/step - loss: 29.5095 - mean_absolute_error: 3.3351\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 6s 622us/step - loss: 27.9794 - mean_absolute_error: 3.2122\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 7s 645us/step - loss: 26.7502 - mean_absolute_error: 3.1037\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 6s 597us/step - loss: 24.9557 - mean_absolute_error: 2.9391\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 6s 551us/step - loss: 23.5008 - mean_absolute_error: 2.8150\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 5s 476us/step - loss: 20.7775 - mean_absolute_error: 2.6662\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 5s 509us/step - loss: 18.1789 - mean_absolute_error: 2.4703\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 5s 529us/step - loss: 16.9959 - mean_absolute_error: 2.3944\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 5s 480us/step - loss: 16.4161 - mean_absolute_error: 2.3150\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 5s 480us/step - loss: 15.1381 - mean_absolute_error: 2.2450\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 5s 474us/step - loss: 14.1863 - mean_absolute_error: 2.1797\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 5s 476us/step - loss: 14.2240 - mean_absolute_error: 2.1662\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 5s 485us/step - loss: 14.3227 - mean_absolute_error: 2.1571\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 5s 503us/step - loss: 13.6644 - mean_absolute_error: 2.1185\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 5s 487us/step - loss: 12.6964 - mean_absolute_error: 2.0335\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 5s 491us/step - loss: 12.4478 - mean_absolute_error: 2.0097\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 12.3681 - mean_absolute_error: 1.9919\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 5s 482us/step - loss: 11.7553 - mean_absolute_error: 1.9568\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 5s 493us/step - loss: 11.1410 - mean_absolute_error: 1.9098\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 11.8557 - mean_absolute_error: 1.9389\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 10.9873 - mean_absolute_error: 1.8905\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 5s 502us/step - loss: 10.7885 - mean_absolute_error: 1.8577\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 5s 486us/step - loss: 10.5365 - mean_absolute_error: 1.8211\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 5s 471us/step - loss: 10.9418 - mean_absolute_error: 1.8321\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 5s 489us/step - loss: 10.5133 - mean_absolute_error: 1.8128\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 5s 522us/step - loss: 10.0106 - mean_absolute_error: 1.7629\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 6s 544us/step - loss: 9.6048 - mean_absolute_error: 1.7390\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 6s 572us/step - loss: 10.0271 - mean_absolute_error: 1.7459\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 6s 597us/step - loss: 9.5344 - mean_absolute_error: 1.7295\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 6s 592us/step - loss: 9.5514 - mean_absolute_error: 1.7252\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 5s 521us/step - loss: 9.5900 - mean_absolute_error: 1.7174\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 5s 505us/step - loss: 9.2818 - mean_absolute_error: 1.7096\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 5s 482us/step - loss: 9.1404 - mean_absolute_error: 1.6770 2s - lo\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 5s 482us/step - loss: 9.1458 - mean_absolute_error: 1.6917\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.8663 - mean_absolute_error: 1.6622\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 4s 429us/step - loss: 9.2812 - mean_absolute_error: 1.6708\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 4s 427us/step - loss: 8.7367 - mean_absolute_error: 1.6541\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 4s 423us/step - loss: 9.1140 - mean_absolute_error: 1.6701\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 6s 577us/step - loss: 8.7978 - mean_absolute_error: 1.6674\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 5s 481us/step - loss: 8.5478 - mean_absolute_error: 1.6401\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.8018 - mean_absolute_error: 1.6453\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 5s 478us/step - loss: 8.5641 - mean_absolute_error: 1.6328\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 5s 481us/step - loss: 8.4396 - mean_absolute_error: 1.6151\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.4194 - mean_absolute_error: 1.6171\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 475us/step - loss: 8.5554 - mean_absolute_error: 1.6230\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 476us/step - loss: 8.3460 - mean_absolute_error: 1.6109\n",
      "Kappa Score: 0.9587622776495751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cv = KFold(len(X), n_folds=5, shuffle=True)\n",
    "results = []\n",
    "y_pred_list = []\n",
    "\n",
    "count = 1\n",
    "for traincv, testcv in cv:\n",
    "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "    \n",
    "    train_essays = X_train['essay']\n",
    "    test_essays = X_test['essay']\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    for essay in train_essays:\n",
    "            # Obtaining all sentences from the training essays.\n",
    "            sentences += essay_to_sentences(essay, remove_stopwords = True)\n",
    "            \n",
    "    # Initializing variables for word2vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "    model.init_sims(replace=True)\n",
    "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "\n",
    "    clean_train_essays = []\n",
    "    \n",
    "    # Generate training and testing data word vectors.\n",
    "    for essay_v in train_essays:\n",
    "        clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
    "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
    "    \n",
    "    clean_test_essays = []\n",
    "    for essay_v in test_essays:\n",
    "        clean_test_essays.append(essay_to_wordlist( essay_v, remove_stopwords=True ))\n",
    "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
    "    \n",
    "    trainDataVecs = np.array(trainDataVecs)\n",
    "    testDataVecs = np.array(testDataVecs)\n",
    "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "    \n",
    "    lstm_model = get_model()\n",
    "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
    "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
    "    y_pred = lstm_model.predict(testDataVecs)\n",
    "    \n",
    "    # Save any one of the 8 models.\n",
    "    if count == 5:\n",
    "         lstm_model.save('./model_weights/final_lstm.h5')\n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)\n",
    "    \n",
    "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "    print(\"Kappa Score: {}\".format(result))\n",
    "    results.append(result)\n",
    "\n",
    "    count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Avg. Kappa Score is 0.961 which is the highest we have ever seen on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Kappa score after a 5-fold cross validation:  0.9613\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Kappa score after a 5-fold cross validation: \",np.around(np.array(results).mean(),decimals=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
